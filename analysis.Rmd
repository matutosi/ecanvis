---
title: "植生調査資料の解析"
author: "松村 俊和"
date: "2025-11-21"
institute: "甲南女子大学"
output:
  # https://github.com/rstudio/revealjs
  revealjs::revealjs_presentation:
    self_contatined: false
    theme: simple
    transition: convex
    css: style.css
    reveal_options:
      slideNumber: true
---

```{r, echo = FALSE, eval = FALSE}
  # rmarkdown::render("D:/matu/work/todo/ecanvis/analysis.Rmd")
  # 
  # https://matutosi.github.io/ecanvis/analysis.html
  # https://matutosi.github.io/ecanvis/analysis.html?print-pdf # PDF印刷用

  # ローカル
  # D:/matu/work/ToDo/ecanvis/analysis.html
  # file:///D:/dropbox/ToDo/ecanvis/analysis.html?Fprint-pdf#/title-slide
```

```{r setup, include = FALSE}
pkg <- "tidyverse"; if(!require(pkg, character.only = TRUE)) install.packages(pkg)
pkg <- "knitr"    ; if(!require(pkg, character.only = TRUE)) install.packages(pkg)
pkg <- "flextable"; if(!require(pkg, character.only = TRUE)) install.packages(pkg)
pkg <- "magrittr" ; if(!require(pkg, character.only = TRUE)) install.packages(pkg)
pkg <- "ecan"     ; if(!require(pkg, character.only = TRUE)) install.packages(pkg)
pkg <- "vegan"    ; if(!require(pkg, character.only = TRUE)) install.packages(pkg) # ecanと同時にインストールされる
pkg <- "ggdendro" ; if(!require(pkg, character.only = TRUE)) install.packages(pkg) # 図示で使用
pkg <- "ggrepel"  ; if(!require(pkg, character.only = TRUE)) install.packages(pkg) # 図示で使用
pkg <- "ggsci"    ; if(!require(pkg, character.only = TRUE)) install.packages(pkg) # 図示で使用
pkg <- "cowplot"  ; if(!require(pkg, character.only = TRUE)) install.packages(pkg) # 図示で使用

knitr::opts_chunk$set( # 警告, メッセージ, エラーの非表示
  warning = FALSE,
  message = FALSE,
  error   = FALSE)

  # Generate table
gen_table <- function(tbl, caption, caption_tex = caption){
  if(knitr::is_latex_output()){
    table <-   # pdf
      tbl |> 
      knitr::kable(format = "latex", booktabs = TRUE, caption = caption_tex)
  }else{
    table <-   # HTML, word
      tbl |>
      flextable::flextable() |>
      flextable::theme_vanilla() |>
      flextable::set_table_properties(align = "left", layout = "autofit") |>
      flextable::set_caption(caption)
  }
  table
}
  # Helper for gen_table()
str2tbl <- function(str, ncol){
  tbl <- matrix(str, ncol = ncol , byrow = TRUE)
  tbl |>
    magrittr::set_colnames(tbl[1,]) |>
    `[`(_, -1, ) |>
    tibble::as_tibble()
}
  # memo：他のオプション
  #                   コード表示  結果  実行
  # eval = FALSE    #     ◯      －    －
  # echo = FALSE    #     －      ◯    ◯
  # include = FALSE #     －      －    ◯
```

# 解説の内容

- 基礎的・一般的な手法を紹介
  - 他にも色々とある
  - 書籍や論文で学ぶ
- 生成AIに質問すれば教えてくれる
  - 基本的な考え方の理解が重要
  - ブラックボックスではダメ
- 間違いがあればご指摘ください

<aside class="notes">
植生学では現地調査によって収集した調査資料を解析することで，植物群集の特徴などを明らかにします．
解析手法には，種多様性指数のような基礎的なものから，種の分布の予測のような応用的なものまで多種多様なものがあります．
各手法の詳細は，専門の書籍や論文によって定義や使い方を学んでください．
本稿では，基礎的かつ一般的な手法を紹介します．
なお，植物社会学的調査方法による表操作は本稿での対象外です．

生成AIに質問すれば色々と教えてくれます．
たとえば，生成AIに調査資料をアップロードして「各地点の種多様性を計算してください」質問するとします．
種数だけでなくShannonのH'やSimpsonの1/dなど多様性指数も回答してくれるかもしれません．
ただし，多様性指数が何を意味するのかの基本的な考え方が理解できなければ，回答を得ても意味がありません．
多様性指数を実際に計算をできなくても構いませんが，全くのブラックボックスではダメです．
</aside>

## 全体像

- 調査資料の取り扱い
- 解析手法の種類
  - 多様性指数
  - クラスター分析
  - 序列化
  - 指標種分析
- 演習編
  - 準備
  - 前処理
  - 解析・図化

<aside class="notes">
まず，調査資料の取り扱い方を説明します．
その後，基本的な解析手法として，多様性指数，クラスター分析，序列化，指標種分析を紹介します．
ここでは，基本的な考え方を中心に説明します．
その後，具体的な調査資料をもとにした演習をします．

Rを使用しますので，事前にインストールしておいてください．
インストール方法は，ネットで検索すれば出てきます．
また，使用するパッケージもインストールする必要があります．
</aside>


# 調査資料の取り扱い

- Tidyな形式で保存
- パソコンへの入力方法
- データの種類と変換

<aside class="notes">
調査資料をパソコンに保存するときに重要なことは，Tidyな形式で保存することです．
人間が理解しやすい植生調査表のような形式は，パソコンには理解しづらいためです．
また，植生調査に関する資料では，地点, 組成, 種と全く異なる形式のものがあり，これらは別々に保存します．
詳細は別途説明します．
場合によっては被度のような量的データを変換する必要があります．
</aside>

## Tidyとは

- Hadley (2014)
- 整然とした状態：データ解析では必須
  - 1つの変数が1つの列
  - 1つの観測が1つの行
  - 1つのタイプの観測群が1つの表
  - 1つの値が1つのセル

<aside class="notes">
Tidyとは，整然としたという意味で，データがパソコンが理解しやすい状態に整理されていることを意味します．
詳細は，Hadley(2014)をご覧ください．

言葉だけみてもわかりにくいので，Excelなどのスプレッドシートに地点情報を入力するとします．
1つの変数が1つの列とは，A列に地点名が，B列に調査日をそれぞれ入力した状態です．
1つの観測が1つの行とは，2行目に1地点目の情報である地点名，調査日，緯度，傾度などを入力した状態です．
なお，1行目には項目名を入力するのが一般的です．
1つのタイプの観測群が1つの表とは，地点情報と組成の情報を別々のシートに入力した状態です．
1つの値が1つのセルとは，A2のセルには1つの値のみが入っている状態です．
</aside>

## Tidy vs Messy

"Happy families are all alike; <br>
every unhappy family is unhappy in its own way."<br>
— Leo Tolstoy

"Tidy datasets are all alike, <br>
but every messy dataset is messy in its own way."<br>
— Hadley Wickham

<aside class="notes">
トルストイの小説『アンナ・カレーニナ』の冒頭に"Happy families are all alike; every unhappy family is unhappy in its own way."という言葉があります．
データも同じで，Hadley Wickham氏は"Tidy datasets are all alike, but every messy dataset is messy in its own way."と述べています．
</aside>

## Messy data

```{r messy}
tidyr::table2
```

<aside class="notes">
これはmessyデータの例です．
このデータは結核症例数を示したものです．
type列にcases(罹患数)とpopulation(人口)という2つの項目があり，その数値がcount列にある点でtidyではありません．
本来は，casesとpopulationは項目名であり，それぞれが別の列に配置されるべきです．
</aside>

## Tidy data

```{r tidy}
tidyr::table2 |>
  tidyr::pivot_wider(
    c(country, year), 
    names_from = type, 
    values_from = count)
```

<aside class="notes">
これはtable2のデータを`tidyr::pivot_wider()`でtidyに整理したものです．
</aside>

## 植生データの種類

- 地点：地点, 緯度, 経度, 標高, 日時, ...
- 組成：地点, 階層, 種名, 被度, ...
- 種：種名, 科, 生活型, 機能型, ...

<aside class="notes">
地点データには, このほかに地形, 天候などもあります．
組成データには, このほかに植物の状態(実生, 開花の有無)などもあります．
種データには, このほかに系統関係などもあります．
</aside>

## パソコンへの入力・保存

- 1行目は項目名
- 空の行，空の列，空のセルはつくらない
- テキストファイル(CSV or TSV)で保存(推奨)
  - 誤変換を防ぐ
  - 再利用が容易
  - `readx::read.xlsx()`，`readr::write_csv()`
- スプレッドシートでの保存
  - 組成, 地点, 種を別シートに入力
  - 文字列として保存(誤変換対策)
  - `openxlsx::write.xlsx()`

<aside class="notes">
調査資料を解析するときには，パソコンにデータを入力します．
入力には，Excel等のスプレッドシートを使うのが楽です．
ただし，入力時の注意点が主に3つあります．
1つ目は，シートの1行目には項目名を入力することです．
2つ目は，空の行，空の列，空のセルはつくらないことです．
特に，見やすさを考慮して1行目や1列目を空けたりするかもしれませんが，これは不要です．
空けないようにしてください．
また，欠損値を空のセルにしたりするかもしれません．
空のセルは，後から見たときに欠損値か入力漏れか判別できません．
欠損値の場合は，"NA"あるいは"-"のような文字列を入力してください．
使用する文字列は任意ですが，実際のデータに含まれないものを使います．
3つ目は，保存するときはCSV(Comma Separated Values，カンマ区切りのテキストファイル)あるいはTSV(Tab Separated Values，タブ区切りのテキストファイル)で保存することを推奨します．
CSVやTSVで保存したデータは，保存・読み込み時に誤変換が起こりにくいです．
文字コードは，UTF-8が一般的です．
また，CSVやTSVはOSによらず読み込み可能ですので，再利用が容易です．

スプレッドシートで保存する際には，組成, 地点, 種を別シートに入力してください．
また，セルの書式を文字列にしておくと，誤変換しにくいでしょう．
</aside>

## データの種類と変換

- 百分率
- Braun-Blanquetの階級値
- 在・不在
- 平方根変換
- 対数変換
- 相対優占度
- Hellinger変換

<aside class="notes">
植生学では，どの地点に，どの種が，どの程度の量で生育していたのかを記録します．
地点や種は名義尺度ですので，そのまま記録します．
どの程度の量生育していたかは，量の測定と記録方法は多くの方法があります．
個体数を記録することもあれば，被度を記録することもあります．
ここでは，被度を記録するとします．
植物社会学では，被度をブラウン・ブランケの階級値を使うことが多いでしょう．
また，被度を百分率で記録することや有無のみを記録することもあります．
百分率のままでは差が大きすぎるときに，平方根や対数によってばらつきを小さくすることができます．

取得したデータを解析のために変換することもあります．
たとえば，階級の中央値への変換や，平方根や対数での変換です．

なお，群度はここでは扱いません．
もちろん，未同定種や種の分類の問題はありますが．

その他，鈴木(1954)のp61，星野(1991)，小林(1995)のp53,54も参考になります．

<!-- 
星野 義延. 1991. 種多様性算出のためのBraun-Blanquetの優占度階級値のパーセント被度値への変換方法. 環境科学会誌, 4, 193-205.
03479.pdf
-->
</aside>

## データの種類と変換

```{r convert-value}
bb_scale <- c("5", "4", "3", "2", "1", "+", "r", "0")
percentage <- c(75, 50, 25, 10, 1, 0.1, 0.01, 0)
percen_med <- (percentage + lag(percentage, default = 100)) / 2
percen_med[length(percen_med)] <- 0
pa <- purrr::map_dbl(percentage > 0, sum)
squared <- percentage^0.5
logged <- log10(percentage + 1) # +1: 1未満を正
tibble::tibble(bb_scale, percentage, percen_med, pa, squared, logged)
```

## 相対優占度

- nij：地点jでの種iの出現量(被度や個体数)
- Nj：地点jの全種の出現量の合計<br>
  Nj = Σnij
- Pij：地点jでの種iの相対優占度<br>
  Pij = nij / Nj

```{r propotion}
val <- c(4, 3, 2, 1)
val / sum(val)
```

<aside class="notes">
単純なデータ変換ではなく，相対値を求める変換として相対優占度の算出があります．
相対優占度とは，ある地点における出現種の出現量(被度や個体数)の相対値で，全出現種の優占度の合計で各出現種の優占度を割ったものです．

ある地点に種aからdまでの4種が生息していたとして，優占度がそれぞれ4,3,2,1であったとします．
合計は10ですので，それぞれの相対優占度は0.4, 0.3, 0.2, 0.1です．
相対値に変換することで，地点ごとの優占度のばらつきを取り除きます．

なお，相対優占度は，多様性指数の計算や類似度の計算で利用します．
</aside>

## Hellinger変換

- 相対優占度の平方根

```{r propotion-square}
val <- c(4, 3, 2, 1)
proportion <- val / sum(val)
proportion ^ 0.5
```

<aside class="notes">
相対優占度を算出した後で平方根を取ることをHellinger変換といいます．
相対優占度によって地点間のばらつきを取り除き，Hellinger変換によって地点内のばらつきを小さくします．
Hellinger変換は，後述するクラスター分析で使用します．
</aside>

# 解析の種類

- 多様性指数：α, β, γ
- 分類：クラスター分析<br>
  TwinSpan, 分類回帰樹木, ...
- 序列化(Ordination)：PCA, PCoA, DCA, nMDS,<br>
  CCA, RDA, ...
- 指標種分析(ISA：Indicator Species Analsis)
- その他
  - Rarefaction Curve
  - 時系列分析
  - 分布モデル

<aside class="notes">
植生調査試料の解析手法は多種多様です．
基本的な手法には，多様性指数の算出から，クラスター分析などを用いた分類，序列化，指標種分析があります．
Rarefaction Curve，時系列分析，分布モデルなどもあります．
目的によって解析手法は異なりますので，自分の研究でしたいことにあった手法を使ってください．
まずは書籍や論文を読んでどのような手法があるのか学んでください．

目的が明確にできているのなら，それをもとに生成AIに相談しても良いかもしれません．
ただし，基本的な考え方については理解することと，研究者自身の最終的な判断することが必要です．
</aside>

# 多様性指数

- α：地点内の多様性<br>
  - 1地点あたりの種数
  - 均等度の考慮の有無
- β：地点間の多様性(類似度)
  - β = γ / α
  - β = γ - α
- γ：地域内の多様性
- 地点・地域の大きさは任意

<aside class="notes">
多様性指数は，生物群集の豊かさを数値化したものです．
種数だけでなく均等度を考慮した指数があります．

生物群集の豊かさは，空間規模が大きくなるほど豊かになります．
そのため，豊かさの表現や比較には空間規模の設定が必要です．
一般的には，空間規模に応じた多様性として，地点内の多様性をα多様性，地点間の多様性をβ多様性，地域内の多様性をγ多様性の3つが使われるます．

α多様性の地点とγ多様性の地域の大きさは任意です．
α多様性の地点としては1つの調査地点を用いて，森林ならば100-400㎡などの規模，草原ならば1-10㎡が使われることが多いです．
γ多様性の地域としては幅が広く，複数個の調査地点，景観規模，市町村単位までの規模が使われます．
β多様性は地点間の多様性であり，γ多様性とα多様性との比率と定義するときと，γ多様性とα多様性との差として定義することがあります．

さらに，地点，地点の複数の集まり，複数の地点の集まりの景観規模，景観規模の集まりの市町村単位，市町村の集まりのの都道府県単位のように入れ子状に考えることもありますWagner(2000)．
<!--
- Helene H. Wagner, Otto Wildi and Klaus C. Ewald. 2000. Additive partitioning of plant species diversity in an agricultural mosaic landscape. Landscape Ecology, 15. 219-227.
-->
</aside>

## α多様性

- 主な指数
  - 種数：S
- Simpsonの均等度
  - d =  Σ(Pij)^2
  - 1 - d：均等度のみ考慮
  - 1 / d：均等度と種数を考慮
- Shannonの情報量：H'
  - H' = -Σ(Pij・ln(Pij))

<aside class="notes">
α多様性の代表的な指数として，種数(S)，Simpsonの均等度指数，Shannonの情報量指数があります．
Sはある地点に出現する種数です．
Simpsonの指数は，本来は集中度指数としてdがあります．
集中度と均等度は反対の概念ですので，その逆数である1/d，1との差である1-dが均等度指数として使われます．

均等度指数では，まず相対優占度を算出します．
各出現種の相対優占度を二乗したものを，合計したものがSimpsonの集中度指数dです．
1つの種に優占度が集中したとき，つまり出現種が1種のときに最大値である1になります．
集中度が低い，つまり多くの種が出現するとき，優占度が出現種で均等であるときは，小さくなります．
全ての種が均等に出現するときには，dは1/Sと等しい値になります．

1 / dは，dの逆数です．
出現種が1種のときに最小値である1で，全ての種が均等であるときには種数であるSと同じです．
1 - Dは，最小値が0で均等であるほど大きくなります．

Shannonの情報量指数は，各種の相対優占度に相対優占度の対数を乗じたものを合計します．
対数の底はe，つまり自然対数を使うことが多いですが，底に2を使うこともあります．
他の研究とH'を比較するときには，対数の底を確認してください．

なお，α多様性と同じ方法でγ多様性も算出します．
</aside>

## Simpsonの均等度指数

```{r d-inv-1}
val <- rep(20, 5)  # 5種とも全て20のとき
nj <- sum(val)     # 出現量の合計
pi <- val / nj     # 相対優占度
d <- sum(pi^2)
c(d, 1/d)
```

```{r d-inv-1-ggplot, echo = FALSE}
x <- seq(val)
label <- letters[x]
tibble::tibble(x = x, y = 1, val = val, label = label) |>
  ggplot2::ggplot(ggplot2::aes(x, y, color = label)) + 
  ggplot2::geom_point(size = (val^0.5) * 5) + 
  ggsci::scale_fill_nejm() + 
  ggplot2::theme_void() + 
  ggplot2::theme(legend.position = "none") + 
  ggplot2::theme(aspect.ratio = 1/4)
```


<aside class="notes">
Simpsonの均等度指数を実際に計算します．
簡単な内容ですので，手入力でRで実行してみましょう．

5種全てが均等な場合です．
わかりやすくするために，合計の出現量が100になるようにしています．
dが0.2で，1/dが種数と同じ5です．
</aside>

## Simpsonの均等度指数

```{r d-inv-2}
val <- c(10, 10, 60, 10, 10) # 1種が60,他が10
nj <- sum(val)     # 出現量の合計
pi <- val / nj     # 相対優占度
d <- sum(pi^2)
c(d, 1/d)
```

```{r d-inv-2-ggplot, echo = FALSE}
x <- seq(val)
label <- letters[x]
tibble::tibble(x = x, y = 1, val = val, label = label) |>
  ggplot2::ggplot(ggplot2::aes(x, y, color = label)) + 
  ggplot2::geom_point(size = (val^0.5) * 5) + 
  ggsci::scale_fill_nejm() + 
  ggplot2::theme_void() + 
  ggplot2::theme(legend.position = "none") + 
  ggplot2::theme(aspect.ratio = 1/4)
```

<aside class="notes">
1種が半分以上を占めている場合です．
dが0.4で，1/dが2.5です．
特定の種が優占しているため，多様性指数が低くなりました．
</aside>

## α多様性のまとめ

- 基本情報としての種数
- 均等度と種数を考慮：1/dが理解しやすい
  - 最小値：1
  - 最大値：S(全種が均等)
- 均等度のみ：1 - d

<aside class="notes">
α多様性のまとめです．
種数は基本的な情報として重要です．
種数と均等度の両方を考慮した多様性指数は，1/dが理解しやすいです．
最長値が1で，最大値が出現種数と同じになるためです．
均等度のみを考慮した指数としては，最小値が0で最大値が1になる1-dがよいでしょう．
</aside>

## β多様性・γ多様性

- β多様性は γ / α または γ - α
  - 一般的にはγ / α
  - 比較の際には定義の確認が必要
- γ多様性の算出方法はα多様性と同様

<aside class="notes">
β多様性は，γ多様性とα多様性の比もしくは差として定義されます．
多くは比を用いていますが，差を用いている場合があります．
そのため，β多様性を比較する際には，定義およびα多様性とγ多様性を求めている空間規模の確認してください．
なお，γ多様性の算出方法はα多様性と同様です．
</aside>

# クラスター分析

- 地点あるいは種を分類
- 地点の分類：種の出現の仕方(類似度)を算出
- 方法
  - 地点(種)間の類似度を計算
  - 「近いもの」を結合
- 類似度と結合方法によって結果が異なる
- グループ内での並び順は無意味

<aside class="notes">
クラスター分析は，地点あるいは種をその出現の仕方に基づいて，クラスターというまとまりに結合していき，地点あるいは種を分類する手法です．
生態学では，地点を分類することが多いです．
地点を分類するときには，地点間の種の出現の仕方，つまり類似度を計算します．
類似度の計算方法には多くの手法があります．
類似度をもとにして「近いもの」を結合していきます．
結合方法にも多くの手法があります．
類似度と結合方法としてどれを使うかによって，結果として得られるクラスターが異なります．
また，グループ内での順序の並びは無意味です．
</aside>

## クラスター分析の考え方：データ

```{r cluster-concept-data}
data(USArrests)
tibble::tibble(USArrests)
```

<aside class="notes">
ggdendroパッケージで紹介されているデータを例として取り上げます．
このデータは，アメリカの各州における逮捕者数です．
</aside>

## クラスター分析の考え方：類似度の計算

```{r cluster-concept-dist}
USArrests |>
  head(8) |>
  stats::dist()
```

<aside class="notes">
犯罪傾向が似た州を明らかにするためにクラスター分析をします．
そのためには，まずは`dist()`類似度を計算します．
ここでは最初の8つだけを計算しています．
</aside>

## クラスター分析の考え方：プロット

```{r cluster-concept-plot, echo = FALSE}
hc <- 
  USArrests |>
  stats::dist() |>
  stats::hclust("average")
ggdendro::ggdendrogram(hc, rotate = FALSE, size = 2)
```

<aside class="notes">
次に，`hclust()`でクラスター分析を実行します．
ここでは群平均法を用いています．
最後に`ggdendrogram()`でプロットしています．
この時にどの類似度でグループを区分するかは任意です．
また，横の並び順は無意味です．
</aside>

## 類似度

- メトリック
  - ユークリッド距離<br>
    ( (x1 - x2)^2 + (y1 - y2)^2 )^0.5
  - Hellinger距離<br>
    Hellinger変換してからユークリッド距離を計算
  - マンハッタン距離(碁盤の目の移動)<br>
    |x1-x2| + |y1-y2|
- 非メトリック
  - Bray-Curtis距離：マンハッタン距離を標準化<br>
    (|x1-x2| + |y1-y2|) / ((x1+x2) + (y1+y2))

<aside class="notes">
類似度は，各地点での種の出現量をもとに計算します．
ユークリッド距離は，点の間の直線距離です．
Hellinger距離は，相対優占度の平方根を取るHellinger変換したもののユークリッド距離を計算したものです．
マンハッタン距離は，碁盤の目の移動距離です．
Bray-Curtis距離は，マンハッタン距離を標準化したものです．
標準化とは，出現量で割ることで標本の大きさの影響をなくすことです．

このうち，ユークリッド距離，Hellinger距離，マンハッタン距離はメトリックであり，Bray-Curtis距離は半メトリックであるといわれます．
メトリックであるためには，非負性，同一律，対称性，三角不等式の4つの条件を満たす必要があります．
非負性とは，距離は必ず0以上であることです．
同一律とは，全く同じ点間の距離は0であることです．
対称性とは，距離abと距離baは等しいことです．
三角不等式とは，aからbへの距離は、任意の第3の点cを経由した距離の和より小さいか等しい，つまり遠回りをする方が近道よりも短くなることはないことです．

Bray-Curtis距離では標準化の影響によって三角不等式を満たさない場合があるためです．
三角不等式を満たすとは，aからbへの距離が，任意の第3の点cを経由した距離の和より小さいことで，遠回りをする方が近道よりも短くなることはないということです．
Bray-Curtis距離では，論理的には三角不等式を満たさないことがあるため，半メトリックな指標とされます．

メトリックな距離とそうでない距離では，クラスター分析や序列化で使える手法が異なります．

なお，SorensenのQS(Quotient of Similarity)は，出現量を在・不在データに変換したものと同じです．

gemini：なお，生態学データの非線形性、特に長勾配の普遍性が認識されるにつれて、非ユークリッド距離に基づく手法が主流となりました。現在、群集構造の全体像を把握し、ベータ多様性を測定する非制約型解析では、生態学的妥当性の高いBray-Curtis距離を入力としたPCoAまたはnMDSが標準的な選択肢となっています。

<!-- 小林(1995)のp26 -->
</aside>


## ユークリッド距離とマンハッタン距離

```{r cluster-distaince-compare, echo = FALSE}
df <- tibble::tibble(x = c(1,2), y = c(1,3))
dist_euc <- 
  df |>
  ggplot2::ggplot(ggplot2::aes(x, y)) + 
  ggplot2::geom_point(ggplot2::aes(size = 1)) + 
  ggplot2::geom_path() + 
  ggplot2::coord_fixed() + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = "none")
df <- tibble::tibble(x = c(1,2,2), y = c(1,1,3), size = c(1,0,1))
dist_man <- 
  df |>
  ggplot2::ggplot(ggplot2::aes(x, y)) + 
  ggplot2::geom_point(ggplot2::aes(size = size)) + 
  ggplot2::geom_path() + 
  ggplot2::coord_fixed() + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = "none")
cowplot::plot_grid(
  dist_euc, dist_man, 
  labels = c('ユークリッド距離', 'マンハッタン距離'))
```

<aside class="notes">
ユークリッド距離とマンハッタン距離は上の図のような違いです．
ユークリッド距離は，いわゆる直線距離です．
マンハッタン距離は，碁盤の目のような道路をとおる時の距離です．
京都の碁盤の目を想像すればわかりやすいと思います．
なお，ニューヨークのマンハッタンが東西の格子状に道路が配置されていることから命名されました．
</aside>

## 主な結合方法

- 最近隣法
  - 説明でよく使われる
  - 欠点：鎖状につながりやすい
- 非加重群平均法(UPGMA)
  - グループ結合後に距離を再計算
  - 非メトリックな距離も可能
- Ward法
  - クラスター内の分散を最小化
  - メトリックな距離のみ

<aside class="notes">
説明でよく使われる結合方法として最近隣法があります．
グループの結合後も，グループ間で最も近い地点のあるグループを結びつけます．
一度だけ類似度を計算すれば良いので，計算量が少ないという利点があります．
グループ結合後に，鎖状あるいは帯状に細長くつながりやすいという欠点があります．

非加重群平均法(UPGMA)は，グループ結合後にグループ間の距離を再計算します．
計算量は多くなるものの，よほど多くの地点でない限り問題になることはほとんどありません．
UPGMAで用いる距離は，メトリックな指標でなくても構いません．

Ward法はクラスター内での分散が小さくなるようにグループを結合します．
分類感度がよく，外れ値の影響を受けにくいとされます．
Ward法で用いる距離は，メトリックな指標であることが必要です．

<!--
https://iit.kke.co.jp/marketingscience/analysis/method/analysis_cluster.html
-->
</aside>

## 結合方法の比較

```{r cluster-method-compare, echo = FALSE}
ggd_min <- 
  USArrests |>
  stats::dist() |>
  stats::hclust("single") |>
  ggdendro::ggdendrogram()
ggd_ave <- 
  USArrests |>
  stats::dist() |>
  stats::hclust("average") |>
  ggdendro::ggdendrogram()
cowplot::plot_grid(
  ggd_min, ggd_ave, 
  labels = c('最近隣法', '群平均法'))
```

<aside class="notes">
アメリカでの犯罪傾向について，最近隣法と群平均法を比較したのがこの図です．
最近隣法では，一旦繋がったものが近いものを吸収するように鎖状に繋がっていく傾向にあります．
そのため取り残されたものがあれば，左端の方に1つだけからなるクラスターが発生しやすいです．
</aside>


## クラスター分析のまとめ

- 地点や種を結合
- 1次元的
- 一般的な組み合わせ
  - Bray-Curtis距離 + 非荷重群平均法
  - Hellinger距離 + Ward法 ("ward.D2")

<aside class="notes">
クラスター分析のまとめです．
ただし，あくまでも個人的見解です．
クラスター分析は，似たような地点や種を結合する手法です．
結合したものは，類似度のみが意味を持ち，グループ内での順序の並びは無意味です．

結局どの組み合わせを使えば良いのかですが，手法として妥当かつよく使われる組み合わせは2つあります．
Bray-Curtis距離をもとに非荷重群平均法で結合する方法と，Hellinger距離をもとにWard法で結合する方法です．

Bray-Curtis距離はマンハッタン距離の標準化であるため，生態学的な意味が理解しやすいです．
ただし，Bray-Curtis距離は厳密にはメトリックではないので，
分類感度がよく，外れ値の影響を受けにくいとされるWard法が使えません．
そのため，メトリック距離ではなくても良い非荷重群平均法が使われます．

メトリックなHellinger距離をもとにしたWard法もよく使われます．
なお，veganやecanの関数の引数では，"ward"ではなく"ward.D2"を使います．
</aside>

# 序列化, Ordination

- 手法は多種多様
  - PCA：主成分分析
  - CA：対応分析
  - DCA：除歪対応分析
  - PCoA：主座標分析
  - nMDS：非計量多次元尺度法
  - CCA：正準相関分析<br>
    長い環境傾度との対応
  - RDA：冗長性分析<br>
    短い環境傾度との対応
- 類似度との組み合わせで結果が異なる

<aside class="notes">
序列化の手法は，Ordinationとも言われます．

その方法は本当に色々とあります．
PCA(主成分分析)自体を使うことはほとんどありませんが，基本的な考え方ですので，最初に説明します．
CA(Correspondence Analysis)の説明は省略しますが，CCAとの関係で必要があれば，別途学んでください．
DCAは場合によって使われることがあります．
PCoAとnMDSは比較的よく用いられます．

環境傾度との対応関係を明らかにする手法としてCCAとRDAがあり，それぞれ長い環境傾度と短い環境傾度のときに用いられます．

クラスター分析と同様に，類似度との組み合わせで結果がことなります．
また，手法によっては使える距離に制限があります．

詳しくは，佐々木ほか(2015)のp30を参考にしてください．
</aside>

## PCA：主成分分析

- Principal Component Analysis
- 次元削減
  - 多変量から相関のない成分で説明
  - 一般的には第1軸と第2軸でほぼ説明
  - 入力はメトリックな距離のみ
- 馬蹄(アーチ)効果

<aside class="notes">
主成分分析は，PCAとよばれることが多い手法で，序列化としてまず説明される手法です．
序列化とは，多変量のデータの次元を削減する手法です．
例えば，50地点の植生調査資料に全体で100種が出現したとします．
地点をもとに考えると，種数と同じ数だけつまり100次元の空間が考えられます．
人間はそもそも，100次元のデータを理解することは困難ですので，この中から重要な成分(主成分)を見つけようというのがPCAです．

100次元のものを次元削減しても，多くの成分が出てきます．
ただし，一般的には第1軸と第2軸でほぼすべてを説明できます．
使用するとしても，実際には第4軸ぐらいまでです．

PCAはその手法の結果として馬蹄効果が現れることがあります．
これは別途説明します．
</aside>

## PCAの考え方

```{r pca-x-y-1, echo = FALSE}
  # --- 1. データの定義とPCAパラメータ ---
  # 元のデータ点
x <- c(160, 165, 170, 175, 190, 172, 168, 185, 162, 171)
y <- c( 61,  70,  79,  74,  78,  80,  61,  82,  67,  75)
  # 平均点
mu_x <- mean(x) # 171.8
mu_y <- mean(y) # 72.8
  # 負荷量 (固有ベクトル)
a11 <-  0.826
a12 <-  0.563
a21 <- -0.563
a22 <-  0.826
  # --- 2. データフレームの作成とセンタリング ---
df_pca <- tibble::tibble(x = x, y = y) |> 
  dplyr::mutate(  # センタリング
    x_c = x - mu_x,
    y_c = y - mu_y
  )
  # --- 3. 投影点の計算関数 ---
calculate_pc1_score <- function(x_c, y_c) {  # PC1スコアを計算する関数
  return(a11 * x_c + a12 * y_c)
}
calculate_pc2_score <- function(x_c, y_c) { # PC2スコアを計算する関数
  return(a21 * x_c + a22 * y_c)
}
  # --- 4. 投影点の計算実行 ---
df_pca <- 
  df_pca |> 
  dplyr::mutate(      # PCスコアの計算
    Z1 = calculate_pc1_score(x_c, y_c),
    Z2 = calculate_pc2_score(x_c, y_c),
    # 1. PC1軸への投影点 (PC2軸に平行な垂線がPC1軸と交差する点)
    x1 = mu_x + Z1 * a11,   # 投影点 x1 = mu_x + Z1 * a11
    y1 = mu_y + Z1 * a12,   # 投影点 y1 = mu_y + Z1 * a12
    # 2. PC2軸への投影点 (PC1軸に平行な垂線がPC2軸と交差する点)
    x2 = mu_x + Z2 * a21, # 投影点 x2 = mu_x + Z2 * a21
    y2 = mu_y + Z2 * a22  # 投影点 y2 = mu_y + Z2 * a22
  )

df_pca |>
  ggplot2::ggplot(ggplot2::aes(x, y)) + # 直線は丸め誤差あり
  ggplot2::geom_point(size = 3) +  # 元の点 (黒)
  ggplot2::coord_fixed() + # 軸のスケールを固定し、PC1とPC2の直交性を視覚的に正しく表現
  ggplot2::theme_bw()
```

<aside class="notes">
説明を簡単にするために，上のようにxとyの2変数のデータがあるとします．
この配置を説明するのに最も良い軸はx軸でもy軸でもありません．
</aside>


## PCAの考え方

```{r pca-x-y-2, echo = FALSE}
df_pca |>
  ggplot2::ggplot(ggplot2::aes(x, y)) + # 直線は丸め誤差あり
  ggplot2::geom_abline(intercept = -44.4, slope = 0.6816, color = "black", linetype = "solid") +
  # --- 2. 垂線の描画 ---
  ggplot2::geom_segment(ggplot2::aes(x = x, y = y, xend = x1, yend = y1), color = "red") +
  # --- 3. 点の描画 ---
  ggplot2::geom_point(size = 3) +  # 元の点 (黒)
  ggplot2::geom_point(ggplot2::aes(x1, y1), col = "red", size = 2, shape = 1) +  # PC1への投影点 (赤)
    # --- 4. テーマ設定 ---
  ggplot2::coord_fixed() + # 軸のスケールを固定し、PC1とPC2の直交性を視覚的に正しく表現
  ggplot2::theme_bw()
```

<aside class="notes">
左下から右上への実線をひいていますが，これがxとyの両方を説明をする最適な軸です．
PCAでは第1軸といいます．
</aside>


## PCAの考え方

```{r pca-x-y-3, echo = FALSE}
df_pca |>
  ggplot2::ggplot(ggplot2::aes(x, y)) + # 直線は丸め誤差あり
  ggplot2::geom_abline(intercept = -44.4, slope = 0.6816, color = "black", linetype = "solid") +
  ggplot2::geom_abline(intercept = 324.8, slope = -1.467, color = "black", linetype = "dashed") +
  # --- 2. 垂線の描画 ---
  #   ggplot2::geom_segment(ggplot2::aes(x = x, y = y, xend = x1, yend = y1), color = "red") +
  ggplot2::geom_segment(ggplot2::aes(x = x, y = y, xend = x2, yend = y2), color = "blue") +
  # --- 3. 点の描画 ---
  ggplot2::geom_point(size = 3) +  # 元の点 (黒)
  #   ggplot2::geom_point(ggplot2::aes(x1, y1), col = "red", size = 2, shape = 1) +  # PC1への投影点 (赤)
  ggplot2::geom_point(ggplot2::aes(x2, y2), col = "blue", size = 2, shape = 1) +  # PC2への投影点 (青)
    # --- 4. テーマ設定 ---
  ggplot2::coord_fixed() + # 軸のスケールを固定し、PC1とPC2の直交性を視覚的に正しく表現
  ggplot2::theme_bw()
```

<aside class="notes">
第1軸と直行する点線が第2軸で第1軸の次に説明の程度の大きい軸です．
今回は2変数でしたので，2軸で全てを説明できましたが，多変量の場合はその変数分の軸があります．

ただし，実際には第1軸と第2軸で多くを説明することができます．
説明する量を寄与率といい，この例では第1軸の寄与率が0.96で，第2軸が0.04です．
</aside>


## 馬蹄(アーチ)効果

- 長い環境傾度
- アーチ状に配置
- 入れ替わりが一定のデータ
    - 類似度だけなら，直線上にならぶはず
    - 類似度が低いはずの地点が近くに配置される

<aside class="notes">
馬蹄効果とは，種の入れ替わりのある長い環境傾度のデータを序列化によって配置したときに，馬蹄(馬のひづめ)形，つまりアーチ状になってしまうことです．
もし，入れ替わりが一定のデータがあったときに，類似度だけを考えるなら直線上に配置されるはずです．
しかし，PCAの第1軸と第2軸で実際に配置すると，全体の配置が馬蹄形になります．
その結果，類似度が低いはずの地点が近くに配置されてしまいます．
これは，PAC以外の他の手法でも現れることがあります．
出現のない地点が多いときに現れやすく，植生データではこのようなことはよく起こります．
しかし，これを直接克服することはできません．
</aside>

## 馬蹄効果の例(データ)

```{r pca-arch, echo = FALSE}
val <- rep(c(1,2,3,2,1), 10)
sp <- paste0("sp", stringr::str_pad(unlist(purrr::map2(1:10, 5:14, `:`)), 2, "left", "0"))
st <- paste0("st", stringr::str_pad(rep(1:10, each = 5), 2, "left", "0"))
df_arch <- tibble::tibble(stand = st, species = sp, val = val)
tbl_arch <- ecan::df2table(df_arch, ab = "val")
```

```{r pca-arch-show, echo = FALSE}
t(tbl_arch)
```

<aside class="notes">
たとえば，10地点，14種からなるデータがあるとします．
地点1から地点10まではきれいな環境傾度に並んでいて，1と2のように隣接した地点の類似度はそれれぞれ同じです．
ですので，1軸上にきれいな地点にならぶことを想定します．
しかし，PCAで解析すると異なる結果になります．
</aside>

## 馬蹄効果の例

```{r pca-arch-plot, echo = FALSE}
pca_arch <- 
  tbl_arch |>
  ecan::ordination(o_method = "pca")
gg_arch <- ecan::ord_plot(pca_arch)
gg_arch
  # gg_arch$layers <- NULL
  # gg_arch + ggplot2::geom_text(size = 8)
```

<aside class="notes">
PCAでプロットすると，上のように，地点1から地点10が馬蹄のようにプロットされます．
環境傾度上では地点1と地点10は最も異なると考えます．
しかし，PCAでは地点1と共通種のない地点6から地点10はどれも類似度は0です．
そのため，このような結果になってしまいます．
</aside>

## DCA：除歪対応分析

- Dtrended Component Analysis
- 植生以外ではあまり使われない

<aside class="notes">
PCAの馬蹄効果を除去するために考えられたのが，DCAです．
ただし，植生学以外ではほとんど用いられることはありません．

DCAでは馬蹄効果を強制的に除去します．
第1軸で出現した馬蹄効果を除去するために，まずは第1軸上で区間を区切ります．
各区間での第2軸の平均地を求めて，各区間の平均が等しくなるように第2軸の数値を計算します．

区間の区切り方は恣意的なもので，その区切り方によって結果が大きく異なります．
つまり，かなり恣意的な再配置ですので批判が多くあります．
そのため，あまり用いられなくなっています．

ただし，植生学をはじめとする生態学では多くの手法が生み出されたという歴史的な経緯を知っておいて損はありません．
</aside>

## PCoA：主座標分析

- Principal Coordinate Analysis
- 元の距離をできるだけ保持した低次元空間
- 任意の距離(Bray-Curtis距離など)が使用可能
- ユークリッド距離ではPCAと同じ結果
- 計算結果は一意に決定

<aside class="notes">
PCoAは，次元削減をするという考え方はPCAと同じです．
PCAはデータの分散を最大化する主成分を見つけます．
一方，PCoAでは元の距離をできるだけ保持しながら低次元空間に変換します．
このような処理の方法が異なります．

また，入力できる距離の性質に違いがあります．
PCAでは距離がメトリックでなければなりません．
一方，任意の距離が使えます．
つまりメトリックでないBray-Curtis距離が使えます．

なお，PCoAでユークリッド距離を使うとPCAと同じ結果になります．
</aside>


## nMDS：非計量多次元尺度法

- non-metric Multidimensional Scaling
- 任意の距離(Bray-Curtis距離など)が使用可能
- 距離の大小関係(順序)を維持した低次元空間
- 非線形・複雑な構造のデータに適している
- 反復計算でStress valueを計算
  - 局所解に陥る可能性あり
  - 軸の向きに意味なし
  - < 0.2：許容範囲
  - < 0.1：良い
  - < 0.05：非常に良い

<aside class="notes">
nMDSは，PCoAと同様に任意の距離が使用可能です．
PCoAとの違う点は，距離そのものではなくて距離の順序を使う点です．
つまり，比率尺度ではなく，順序尺度として使います．

nMDSでは反復計算をしますので，毎回同じ結果になるとは限りません．
場合によっては局所解に陥る可能性があり，正しい結果が得られない可能性があります．
また，軸の向きに意味はありません．
なお，Rでは`set.seed()`で乱数種を設定すれば，同じ結果を得ることができます．

gemini：PCoAは，非ユークリッド距離であるBray-Curtis距離を計量的に表現し，NMDSはその順序関係に対する堅牢性で優れています．
</aside>

## CCA：正準相関分析とRDA：冗長性分析

- Canonical Correspondence Analysis
    - CAの環境要因対応版
    - 任意の距離
    - 環境変数の幅が長いとき
- Redundancy Analysis
    - PCAの環境変数対応版
    - メトリックな距離
    - 環境変数の幅が短いとき

<aside class="notes">
CCAとRDAは環境要因などの説明変数を用いて、種の組成や地点の類似性などの応答変数の変動を分析・可視化するために使われます．

CCAはCA(Correspondence Analysis：対応分析)の環境要因対応版です．
任意の距離を使用することができ，環境変数の幅が長いときに使います．

RDAはPCAの環境要因対応版です．
メトリックな距離のみを使うことができ，環境変数の幅が短いときに追加います．

ベータ多様性が低く，つまり地点間の類似度が高いときにはRDAを使います．
ベータ多様性が高くて，ゼロが多く含まれるようなな地点間の類似度が低いときにCCAを使います．
</aside>


## 序列化のまとめ

- 2次元座標への配置<br>
  本当は多次元だが, 実質的には2次元が多い
- Bray-Curtis距離 + PCoA or nMDS
- 環境要因対応版
  - 長い傾度：CCA
  - 短い傾度：RDA

<aside class="notes">
序列化は，主要な成分として多次元への配置をするものです．


実際によく使われる序列化手法は，Bray-Curtis距離をもとにしたPCoAとBray-Curtis距離をもとにしたnMDSです．

環境傾度との関係を分析する場合は，CCAかRDAを使います．
環境傾度が長いときはCCAを，短いときにはRDAを使うことが多いです．
ただし，これは相対的なものですので，まずは両方を試して考えても良いかもしれません．
</aside>

# 指標種分析

- 特定のグループに特徴的に出現する種を抽出
- 在・不在，出現量のどちらでも可能
- Dufrene and Legendre (1997)
- 無作為化検定(Permutation test)が可能

<aside class="notes">
指標種分析は，グループ分けした地点に特徴的に出現する種を明らかにするものです．
出現の有無を使うこともできますし，出現量を使うことも可能です．

Indicator Species Analysisは，無作為化検定(Permutation test)によって統計的な有意性を計算できます．
なお，無作為化検定とはランダムに並べ替えることを繰り返して統計量の分布を求めるノンパラメトリック検定です．

詳細は，Dufrene and Legendre (1997)をご覧ください．
</aside>

## 指標値の計算

- IV = (Cij / Ci) * (Fij/ Fj) * 100
  - Cij：種iのグループjでの出現量
  - Ci：種iの全体での出現量
  - Fij：種iのグループjでの出現回数
  - Fj：種iの全体での出現回数

<aside class="notes">
種iのグループjでの指標値を計算するとします．

種iのグループjでの出現量を種iの全体での出現量で割ります．
これは，グループjでの出現量が高いほど大きな値になります．

また，種iのグループjでの出現回数を種iの全体での出現回数で割ります．
これは，グループjでの出現頻度が高いほど大きな値になります．

つまり，グループjでの出現量や出現頻度が高いほど大きな値になります．
この値は，0-1の間になりますので，%で示すには100倍します．
</aside>

# データ分析の実演

- パッケージの準備
- veganパッケージのデータ
- 前処理：かなり重要
- α多様性
- クラスター分析
- 序列化
- 指標種分析

<aside class="notes">
ここからは実際にデータ分析をします．
準備としてRをインストールしてください．
また，植生解析のためのパッケージであるvean等のパッケージもインストールしてください．

本来は自身のデータを使うのが一番良いのですが，ここではveganに含まれるデータを使用します．
veganのデータもそうですが，すべてのデータがtidyであるとは限りません．
前処理がデータ分析の8割を占めると言われることもあるように，前処理はかなり重要です．
分析の前に前処理を少しします．

その後実際のデータ分析としてα多様性の計算，クラスター分析，序列化，指標種分析を実行します．
Rのコードは次に示すところから入手可能です．
また，それぞれの分析手法のすべてを実行するわけではありません．
細かな点は，関数の引数を変更すれば実行可能なことが多いです．
場合によっては，事前のデータ変換が必要です．
</aside>

## 参考URL

- https://matutosi.github.io/ecan/ とほぼ同じ内容
- https://matutosi.shinyapps.io/ecanvis/ でも実行可能

<aside class="notes">
実行する内容は，githubのecanの解説ページとほぼ同じです．
shinyを使ったページでも同じようなことを実行可能です．

それぞれ参考にしてください．
</aside>

# 準備：パッケージのインストール

```{r install-packages, eval = FALSE}
install.packages("tidyverse") # コードを明快に
install.packages("vegan")     # 植生解析の定番
install.packages("ecan")      # 解析を簡単に
install.packages("ggdendro")  # 図示で使用
install.packages("ggrepel")   # 図示で使用
install.packages("ggsci")     # 図示で使用
install.packages("cowplot")   # 図示で使用
```

<aside class="notes">
各種パッケージを事前にインストールしてください．
このコードは，1回だけ実行すれば構いません．

tidyverseは，コードを明快にするためのものです．
tidyverseは，tibble，tidyr，dplyr，purrr，ggplot2などのパッケージを含むパッケージ群です．

植生解析以外のコードを書くときに役立ちます．
veganは，植生データ解析の定番パッケージです．
ecanをインストールするときに同時にインストールされます．
もちろん，個別にインストールしても構いません．

クラスター分析や序列化は，手法が多くあります．
それぞれの手法が複数のパッケージにまたがっています．
パッケージごとに引数の指定の仕方が異なっています．
また，返り値の仕様もバラバラです．

バラバラの引数や返り値を使いやすくするためにecanというパッケージをまとめました．
いわばパッケージのラッパーのパッケージです．

これらの他に，ggdendroとggrepelというパッケージを図示で使用しますので，インストールしてください．
</aside>

## 準備：パッケージの呼び出し

```{r, echo = FALSE}
library(vegan)
library(ecan)
library(tibble)
library(tidyr)
library(dplyr)
library(purrr)
library(ggplot2)
library(ggdendro)
library(ggrepel)
```

```{r load-library, eval = FALSE}
library(vegan)
library(ecan)
library(tidyverse)
library(ggdendro)
library(ggrepel)
```

<aside class="notes">
パッケージを呼び出しておきます．
コード中ではパッケージ名をできるだけ明示しています．
たとえば，`dplyr::select()`はdplyrパッケージの`select()`という関数です．
ただし，`library()`でパッケージを呼び出しておけば，パッケージ名の明示は不要です．
</aside>

# 基本データの準備(演習)

- データの読み込み
- 前処理
- 結合

<aside class="notes">
解析をするときには，データの準備が必要です．
データの読み込みをした後に前処理が必要です．
はじめからtidyなデータであれば難しくありません．
でもmessyなデータの場合や，他人のデータを使うときなどはデータの構造がわからず，前処理にかなりの時間と労力がかかることがあります．
地点，組成，種に関するデータがtidyなものになれば，あとは結合をすれば準備が完了します．
</aside>

## データの読み込み(例)

```{r read-data, eval = FALSE}
  # CSVのとき
path_stand <- "c:/hoge/huga/stand.csv"
df_st <- readr::read_csv(path_stand)
  # Excelのとき
path_data <- "c:/hoge/huga/data.xlsx"
df_st <- openxlsx::read.xlsx(path_data, sheet = 1)
```

<aside class="notes">
CSVからデータを読み込むときはreadrの`read_csv()`を使うのが良いでしょう．
引数として各データの種類やスキップする行なども指定できます．
詳しくはドキュメントを見てください．

Excel形式のデータを読み込むときはopenxlsxの`read.xlsx()`を使うのが良いでしょう．
シート名が複数あるときは，引数`sheet`でシート番号がシート名を指定してください．
こちらも，詳しくはドキュメントを見てください．
すべてのシートを読み込むときは，松村(2025)の第2章の関数を参考にしてください．
</aside>

## dune.envデータ(地点)

```{r dune-env}
data(dune.env, package = "vegan") # 地点
dune_env_df <- 
  tibble::tibble(dune.env) |> # A1, Moistureなどの情報
  tibble::rownames_to_column("stand") |> # 地点名を列に変換
  print(n = 8)                           # 8行のみ
```

<aside class="notes">
地点データとして，veganの`dune.env`を使用します．
行ラベルとして使われている地点名を独立した列に変換します．
</aside>

## duneデータ(組成)

```{r dune}
data(dune, package = "vegan") # 組成
tibble(dune) |>         # 0-9の値
  dplyr::select(1:5) |> # 5列のみ表示
  print(n = 8)          # 8行のみ
```

<aside class="notes">
組成データとして，veganの`dune`を使用します．
このデータはtidyではありません．
地点のデータが列に，種のデータが行になっています．
</aside>

## duneデータの変換

```{r dune-df}
dune_df <- 
  dune |>         # 組成表形式
  ecan::table2df( # df形式に変換
    st = "stand", 
    sp = "species", 
    ab = "cover")
dune_df
```

<aside class="notes">
tidyにするために，ecanの`table2df()`を使います．
地点，種，出現量のデータが`stand`，`species`，`cover`の列になっています．
</aside>

## 種データ(ダミー)

```{r sp-dummy}
sp_dummy <- tibble::tibble(
  "species" = colnames(dune), 
  "dummy_1" = stringr::str_sub(colnames(dune), 1, 1), # 1文字目
  "dummy_6" = stringr::str_sub(colnames(dune), 6, 6)) # 6文字目
print(sp_dummy, n = 8)
```

<aside class="notes">
veganには種のデータがありません．
そこで架空の種データをでっち上げます．
種名の1文字目と6文字目を名義尺度の種データとします．
</aside>

## 結合

```{r join}
df <- 
    dune_df |>                       # 組成
    dplyr::left_join(dune_env_df) |> # 地点
    dplyr::left_join(sp_dummy)       # 種
```

<aside class="notes">
組成に地点と種のデータをそれぞれ結合します．
組成と地点は地点名(stand)で，種データとは種名(species)で結合します．
</aside>

## 結合：基本データの完成!

```{r joined-show}
df |>
  dplyr::select(1:5, 9:10) |>
  print(n = 8)
```

<aside class="notes">
基本データが完成しました．
なお，列が多いので，`select()`で列を選択しています．
</aside>

# α多様性(演習)

- s: 種数
- h: Shannon's H'
- d: Simpson's index (1 - D)
- i: Simpson's inverse (1 / D)

<aside class="notes">
まずは，α多様性を計算します．
種数，ShannonのH'，Simpsonの指数(1-dと1/d)の4つです．
</aside>

## α多様性の計算

```{r diversity}
div <- ecan::shdi(df)
print(div, n = 8)
```

<aside class="notes">
ecanの`shdi()`を使うと4つを一度に計算できます．
なお，ここでは引数にデータフレームのみを指定しています．
省略するとデータフレームの1列目が地点名，2列が種名，3列名が出現量として扱われます．
地点名，種名，出現量の列名を指定する場合は，引数`stand`，`species`，`abundance`に文字列で指定します．
</aside>

## α多様性(グループ別の平均値)

```{r diversity-group}
dune_env_df <- 
  dplyr::left_join(dune_env_df, div) # 地点を結合
dune_env_df |>
  dplyr::group_by(Management) |> # Managementでグループ化
  dplyr::summarise_if(is.numeric, mean) # 数値の列で平均
```

<aside class="notes">
ここでは地点の属性別での平均値を求めます．
そのためには，まず地点データを結合します．
その後で`group_by()`でグループ化して，`summarise_if()`で数値の列で平均値を求めます．
</aside>

## α多様性の図示(コード)

```{r diversity-ggplot}
diversity_gg <- 
  dune_env_df |>
  ggplot2::ggplot(
    ggplot2::aes(x = Management, y = i)) + # 1 / d
  ggplot2::geom_boxplot(outlier.shape = NA) +
  ggplot2::geom_jitter(height = 0, width = 0.1) + 
  ggplot2::theme_bw() 
```

<aside class="notes">
平均値も大事ですが，全体の様子を確認するために，1 / dの箱ひげ図を作成します．
箱ひげ図では，個別の点が表示されませんので，あわせて地点別のデータも図示します．
`ggplot()`でx軸にManagementを，y軸にi(1/d)を指定します．
箱ひげ図を描画する`geom_boxplot()`では引数で`outlier.shape = NA`を指定して外れ値を非表示にします．
外れ値を非表示にするのは，`geom_jitter()`による個別の点の表示との重複を避けるためです．
</aside>

## α多様性の図示

```{r diversity-ggplot-show}
diversity_gg
```

<aside class="notes">
作図したものを図示します．
論文で使うときには，作図全体のテーマや軸ラベルなどを変更する必要があります．
ggplot2の詳細は，ggplot2のページを参考にしてください．
https://ggplot2-book.org/
日本語板は，今のところ初版分しかなくて，ちょっと情報が古いです．
ggplot2について詳しく知りたいときは，『Rグラフィックスクックブック 第2版』が良いかもしれません．
概要であれば，『Rによる自動化・効率化レシピ集』にも掲載しています．
</aside>

# クラスター分析(演習)

```{r cluster}
cls <- 
  df |>
  ecan::df2table() |> # 組成形式に変換
  ecan::cluster(
    c_method = "average", # 非荷重群平均方
    d_method = "bray")    # Bray-Curtis距離
cls # 結果の表示(実施方法のみ)
```

<aside class="notes">
次に，クラスター分析の演習です．
クラスター分析はecanの関数`cluster()`で実行できます．
`cluster()`の引数には組成表の形式がを渡す必要があります．
ただし，この組成表の形式は通常の組成表とは縦横を転置したものです．
ですので，実行前に`df2table()'で変換します．
結合方法として`c_method = "average"`で非荷重群平均方を，距離を`d_method = "bray"`でBray-Curtis距離を指定します．

クラスター分析の結果を表示するには，`cluster()`の結果を代入したオブジェクトを表示させます．
ただし，そのままでは大した情報は得られません．
</aside>

## クラスター分析の結果

```{r cluster-result}
str(cls)
```

<aside class="notes">
詳細な情報を得るには，関数`str()`を使います．
`str()`はstruscureの省略で，オブジェクトの構造を出力します．
そのため，どのようなデータが入っているのかわかります．
とはいっても，これだけでは結果はよく分かりません．
やはり図示する必要があります．
</aside>

## クラスター分析結果の図示

```{r cluster-plot}
library(ggdendro)
ggdendro::ggdendrogram(cls)
```

<aside class="notes">
クラスター分析の結果を図示するには単に`plot()`とするだけでも可能です．
ただし，ここでは，ggdendroの`ggdendrogram()`を使います．
</aside>

## クラスター分析(グループ追加)

```{r cluster-plot-group-prep}
indiv <- "stand"
group <- "Use"
cls_group <- 
  ecan::cls_add_group(
    cls = cls, 
    df = dune_env_df, 
    indiv = indiv, 
    group = group)
```

<aside class="notes">
地点をグループ分けしたときには，どの地点がどのグループに属しているのかわかりやすく表示したいものです．
そこで，地点名にグループ名を追加して表示させます．
ここでは，
第1引数にクラスター分析の結果である`cls`を，
第2引数に分析前の地点データである`dune_env_df`を，
第3引数に`dune_env_df`での個別の地点名を示す列名として`"stand"`を，
第4引数に`dune_env_df`でのグルー名を示す列名として`"Use"`を指定します．
</aside>

## クラスター分析(グループ別で図示)


```{r cluster-plot-group}
ggdendro::ggdendrogram(cls_group)
```

<aside class="notes">
`ggdendrogram()`で図示すると，グループ名を含む

なお，地点名とグループ名と地点名のそれぞれの文字列の長さを調整するためにアンダースコア`_`が入っています．
でも，英文字では等幅フォントではないので，それほどうまく機能していません．フォントを等幅のものにしていすれば，より綺麗な表示になるはずです．

Rでのフォントの話をするとややこしいので，ここでは省略します．
Rでのggplot2でのフォントの使い方の詳細は，松村(2025)の第2章第7節を参照してください．
</aside>

## クラスター分析(グループで着色)

```{r cluster-plot-group-color}
col <- 
  ecan::cls_color(
    cls = cls, 
    df = dune_env_df, 
    indiv = indiv, 
    group = group)
cls_colored <- stats::as.dendrogram(cls_group)
```

<aside class="notes">
さらに見やすくするために，グループ別で着色する場合は，ecanの`cls_color()`を使います．
また，グループ名を追加したオブジェクト`cls_group`を`as.dendrogram()`で樹状図の形式に変換しておきます．

このあたりの変換は，パッケージecanを作ったときに色々と試した結果です．
ただ，正直なところ詳細は忘れてしまいました．

<!-- dendextend::labels_colors(cls_colored) <- gray(0) # 必要? -->
</aside>

## クラスター分析(着色して図示，コード)

```{r cluster-plot-group-color-plot-prep, eval = FALSE}
plot(cls_colored)
dendextend::colored_bars(
  colors = col, 
  cls_colored, 
  group, 
  y_shift = 0, 
  y_scale = 3)
par(new = TRUE)
plot(cls_colored)
```

<aside class="notes">
着色した結果を表示するときは，`plot()`を使います．
まず，1つ目の`plot()`でプロットします．
その後，dendextendの`colored_bars()`で着色します．
さらに，2つ目の`plot()`で地点名のところを上書きします．

たしか，そんな感じだと思いますが，このあたりの詳細も忘れてしまっています．
すみません．
</aside>

## クラスター分析(着色して図示)

```{r cluster-plot-group-color-plot, echo = FALSE}
plot(cls_colored)
dendextend::colored_bars(
  colors = col, 
  cls_colored, 
  group, 
  y_shift = 0, 
  y_scale = 3)
par(new = TRUE)
plot(cls_colored)
```

<aside class="notes">
</aside>

# 序列化(演習)

- nMDS
- Bray-Curtis距離
- 地点でプロット
- 種でプロット + 色付き

<aside class="notes">
ここでは序列化手法として，nMDSをBray-Curtis距離で実行します．
その結果を地点でプロットします．
また，種でプロットしてグループごとで色をつけます．
同様の方法で地点のプロットにもグループ別で着色可能です．
</aside>

## 序列化：nMDS，Bray-Curtis距離

```{r nmds}
ord_nmds <- 
  df |>
  df2table() |>
  ecan::ordination(
    o_method = "nmds", 
    d_method = "bray")
```

<aside class="notes">
序列化を実行するには，ecanの関数`ordination()`を使います．
`cluster()`と同様に，事前に組成表を転置した形式に変換します．
`o_method = "nmds"`で序列化手法としてnMDSを，`d_method = "bray"`でBray-Curtis距離を指定します．

`ordination()`は，指定した序列化手法に従って，別のパッケージを使ってPCA，PCoA，nMDSなどを実行します．
また，実行結果を整理して返します．

なお，PCAを実行結果を表示したときに，`distance_method`が`"bray"`と表示されます．
PCAでは距離を指定する必要がありませんので，これは間違いです．
いつになるか分かりませんが，ecanの次の更新時に修正します．
</aside>

## 序列化：地点の図示の準備

```{r nmds-plot-st-prep-data}
ord_nmds_st <- 
  ecan::ord_extract_score(ord_nmds, score = "st_scores") |>
  tibble::tibble() |>
  print(n = 10)
```
<aside class="notes">
序列化の結果の一部を取り出すにはecanの関数`ord_extract_score()`を使います．
ここでは，`score = "st_scores"`と地点データを取得します．
</aside>

## 序列化：地点の図示(コード)

```{r nmds-plot-st-prep, eval = FALSE}
ord_nmds_st |>
  ggplot2::ggplot(
    ggplot2::aes(V1, V2, label = .data[["rowname"]])) +
  ggplot2::geom_text() +
  ggplot2::theme_bw()
```

<aside class="notes">
`ord_extract_score()`で抽出した`ord_nmds_st`は単なるデータフレームです．
そのため，ggplot2でプロットするのは容易です．
</aside>

## 序列化：地点の図示

```{r nmds-plot-st, echo = FALSE}
ord_nmds_st |>
  ggplot2::ggplot(
    ggplot2::aes(V1, V2, label = .data[["rowname"]])) +
  ggplot2::geom_text() +
  ggplot2::theme_bw()
```

<aside class="notes">
</aside>

## 序列化：種の図示の準備

```{r nmds-plot-sp-prep}
indiv <- "species"
group <- "dummy_1"
ord_nmds_sp <- 
  ecan::ord_add_group( # 抽出も実行
    ord = ord_nmds, 
    score = "sp_scores", 
    df = df, 
    indiv = indiv, 
    group = group)
```

<aside class="notes">
次に，種をグループで着色してプロットします．
ecanの関数`ord_add_group()`で序列化の結果にグループ名を追加します．
第1引数に`ord = ord_nmds`として序列化の結果を，
第2引数に`score = "sp_scores"`として種のデータを，
第3引数に`df = df`として地点とグループ名の対応のあるもとのデータフレームを，
第4引数に`indiv = indiv`として個別の種名を示す列名`"species"`
第5引数に`group = group`としてグルー名を示す列名`"dummy_1"`を指定します．

余談ですが，今回の資料を準備していてecanのバグを見つけました．
上では`group = group`としてグループ名を指定していますが，関数の中では使っていませんでした．
このあたりの次回のecanの更新で修正します(引数から除外するか，ちゃんと使うか)．
</aside>

## 序列化：種の図示用のデータ

```{r nmds-plot-sp-prep-show}
tibble::tibble(ord_nmds_sp)
```

<aside class="notes">
`ord_add_group()`で得た結果は，データフレームです．
そのため，ggplot2でプロットするのは簡単です．
</aside>

## 序列化：種の図示

```{r nmds-plot-sp-plot-prep, eval = FALSE}
ord_nmds_sp |>
  ggplot2::ggplot(
    ggplot2::aes(V1, V2, 
      label = .data[[indiv]])) +
  ggplot2::geom_point(
    ggplot2::aes(
      col = .data[[group]]), 
      alpha = 0.4, 
      size = 7) +
  ggplot2::geom_text() +
  ggplot2::theme_bw()
```

<aside class="notes">
種名をラベルとして表示するために，`label = .data[[indiv]]`としています．
さらに，種名に丸で色付けするために`geom_point()`を使います．
引数として，`col = .data[[group]]` でグループ別に色をつけるようにして，
`alpha = 0.4`で透明度を，`size = 7`で大きさを指定します．
`ggplot2::geom_text()`は`geom_point()`の後にすることで，丸印を先に描画してその上に種名を描画します．
</aside>

## 序列化：種の図示

```{r nmds-plot-sp-plot, echo = FALSE}
ord_nmds_sp |>
  ggplot2::ggplot(ggplot2::aes(V1, V2, label = .data[[indiv]])) +
  geom_point(ggplot2::aes(col = .data[[group]]), alpha = 0.4, size = 7) +
  ggplot2::geom_text() +
  ggplot2::theme_bw()
```

<aside class="notes">
</aside>

# 指標種分析(演習)

```{r indval, eval = FALSE}
  # `row_data = TRUE`でlabdsv::indval()のそのままの結果
isa_res_raw <- 
  ecan::ind_val(df, 
          group = "Management", 
          row_data = TRUE)
  # 以下の出力は省略
isa_res_raw$relfrq # 種の出現頻度
isa_res_raw$relabu # 種の平均出現量
isa_res_raw$indval # 指標値
tibble(
  cls = isa_res_raw$maxcls,     # 最大値のクラス
  ind_val = isa_res_raw$indcls, # 指標値
  p = isa_res_raw$pval)         # p値
```

<aside class="notes">
指標種分析にはecanの関数`ind_val()`を使います．
引数に`row_data = TRUE`を指定するとlabdsvの関数`indval()`をそのまま返します．
返り値の詳細は，`indval()`のヘルプを参照してください．
</aside>

## 指標種分析の結果：整理した結果

```{r indval-res}
group <- "Management"
(isa_res <- ecan::ind_val(df, group = group))
```

<aside class="notes">
論文や図示で使うには，`indval()`から得た情報から必要なものを抽出する必要があります．
その場合には，`row_data = TRUE`を指定せず既定値(`row_data = FALSE`)のまま実行します．
ここでは，グループ名として`group <- "Management"`を指定します．
整理した結果として，グループ名，種名，指標値，p値からなるデータフレームを返します．
</aside>

## 指標種分析の結果の図示(コード)

```{r indval-plot}
isa_gg <- 
  isa_res |>
   ggplot2::ggplot(
    ggplot2::aes(
      x = .data[[group]], 
      y = .data[["ind.val"]],
      size = log(1 / (.data[["p.value"]] * 10)),
      label = .data[["species"]])) + 
  ggplot2::geom_point() + 
  ggrepel::geom_text_repel(
    ggplot2::aes(
      size = log(1 / (.data[["p.value"]] * 10), base = 5))) + 
  ggplot2::theme_bw() + 
    ggplot2::theme(legend.position = "none")
```

<aside class="notes">
指標種分析の結果を図化します．
x軸にグループ名を，y軸に指標値を，p値を点と文字列の大きさにして，種名をプロットします．
ここでは，作図オブジェクトを`isa_gg`に代入します．
</aside>

## 指標種分析の結果の図示

```{r indval-plot-show}
isa_gg
```

<aside class="notes">
isa_ggを入力すると，図が表示されます．
</aside>

# 引用文献

- Hadley, W., 2014, Tidy data. Journal of Statistical Software, 59, 1-23.
- Dufrene, M. and Legendre, P. 1997. Species assemblages and indicator species: the need for a flexible asymmetrical approach. Ecol. Monogr. 67, 345-366.

<aside class="notes">
Hadley(2014)は，Tidyデータについてです．
Dufrene and Legendre(1997)は，指標種分析の説明です．
</aside>

## 書籍

- 佐々木 雄大・小山 明日香・小柳 知代・古川 拓哉・内田 圭. 2015. 生物群集の構造と多様性の解析. 共立出版. 
- Wildi, Otto. 2017. Data Analysis in Vegetation Ecology, 3rd ed. Cabi.
- 小林 四郎. 1995. 生物群集の多変量解析. 蒼樹書房. 
  絶版．中古がネット書店に．
- 伊藤 秀三(編). 2003. 群落の組成と構造. 朝倉書店. 
  1977年に出版し, 絶版．2003年に復刊し, 絶版．
  中古がネット書店に．

<aside class="notes">
佐々木ほか(2015)では植生をはじめとする植物群集の解析全般が解説されています．
小林(1995)は，クラスター分析や序列化の手法について詳しい解説があります．
Wildi(2017)も多変量解析について解説しています．
伊藤(2003)は多変量解析についてではありませんが，参考になります．

<!-- - 鈴木時夫. 1954. 生態調査法. 古今書院.  -->
</aside>

## 全般的な解説

- 加藤 和弘. 1996. 生物群集の多変量解析とその地域環境計画への応用. ランドスケープ研究, 60, 46-55.
- 大垣俊一. 1999. 群集組成の多変量解析. Argonauta, 1, 15-26.
- 大垣俊一. 2008. 多様度と類似度、分類学的新指標. Argonauta. 15, 10-22.
- 土居 秀幸・岡村 寛. 2011. 生物群集解析のための類似度とその応用: Rを使った類似度の算出, グラフ化, 検定. 日本生態学会誌, 61, 3-20. 

<aside class="notes">
多変量解析などについて全般的な解説が総説などであります．
これらも参考にしてください．
</aside>

# 植生学会への入会案内

- 植生学会<br>
  http://shokusei.jp/baser/
- 入会案内<br>
  http://shokusei.jp/baser/contact/admission-and-withdrawal

# アンケートのお願い

- 匿名式
- URL(2つとも同じ)
  - https://forms.gle/WPXZ6p94dvDoJxQB6
  - https://docs.google.com/forms/d/e/1FAIpQLScXq-97_MIAFc30VLl6v5HQj8HEebAf__y_oTn7si2t2bSo6Q/viewform

# Rで自動化・効率化(宣伝)

- 松村 俊和. 2025. <br>Rによる自動化・効率化レシピ集. 森北出版.
  - https://github.com/matutosi/r-auto<br>(サポートページ)
  - https://www.amazon.co.jp/dp/4627858310/<br>(Amazon)

<aside class="notes">
最後に宣伝です．
多変量解析については書いていませんが，Rでいろいろなことをするのに役立つと思ます．
興味があれば，お求めください．
</aside>
